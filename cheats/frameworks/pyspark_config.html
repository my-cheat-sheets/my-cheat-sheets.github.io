<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>PySpark Config Cheatsheet</title>
</head>

<body>
    <h1>PySpark Config Cheatsheet</h1>

    <details open>
        <summary>session">
            <h2>Spark Session & Basic Config</h2>
            <ul>
                <ol><strong>SparkSession Builder</strong>
                    <pre><code class="language-python">
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("MyApp") \
    .master("local[*]") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()
                </code></pre>
                </ol>
                <ol><strong>Common Properties</strong>
                    <pre><code class="language-properties">
# Application Name
spark.app.name = MySparkApp

# Master URL (yarn, local[n], mesos://, spark://)
spark.master = yarn

# Driver Memory (Amount of memory to use for the driver process)
spark.driver.memory = 4g

# Executor Memory (Amount of memory to use per executor process)
spark.executor.memory = 8g

# Executor Cores (Number of cores to use on each executor)
spark.executor.cores = 4
                </code></pre>
                </ol>
            </ul>


            <details>
                <summary>tuning">
                    <h2>Performance Tuning</h2>
                    <ul>
                        <ol><strong>Shuffle Partitions</strong>
                            <pre><code class="language-properties">
# Default is 200. Adjust based on data size.
# Too high = overhead, Too low = skew/OOM.
spark.sql.shuffle.partitions = 500
                </code></pre>
                        </ol>
                        <ol><strong>Dynamic Allocation</strong>
                            <pre><code class="language-properties">
# Scales executors up and down based on workload
spark.dynamicAllocation.enabled = true
spark.dynamicAllocation.minExecutors = 2
spark.dynamicAllocation.maxExecutors = 50
spark.dynamicAllocation.initialExecutors = 5
spark.shuffle.service.enabled = true
                </code></pre>
                        </ol>
                        <ol><strong>Memory Management</strong>
                            <pre><code class="language-properties">
# Fraction of heap used for execution and storage (Unified Memory) (default 0.6)
spark.memory.fraction = 0.75

# Fraction of spark.memory.fraction used for storage (cache) vs execution (shuffle) (default 0.5)
spark.memory.storageFraction = 0.5

# Off-heap memory
spark.memory.offHeap.enabled = true
spark.memory.offHeap.size = 2g
                </code></pre>
                        </ol>
                        <ol><strong>Serialization</strong>
                            <pre><code class="language-properties">
# Use Kryo serialization for better performance than Java serialization
spark.serializer = org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired = false
                </code></pre>
                        </ol>
                        <ol><strong>Adaptive Query Execution (AQE) - Spark 3.0+</strong>
                            <pre><code class="language-properties">
spark.sql.adaptive.enabled = true
spark.sql.adaptive.coalescePartitions.enabled = true
spark.sql.adaptive.skewJoin.enabled = true
                </code></pre>
                        </ol>
                    </ul>


                    <details>
                        <summary>ui-logging">
                            <h2>UI & Logging</h2>
                            <ul>
                                <ol><strong>Event Log</strong>
                                    <pre><code class="language-properties">
# Enable event logging for History Server
spark.eventLog.enabled = true
spark.eventLog.dir = hdfs:///var/log/spark
                </code></pre>
                                </ol>
                                <ol><strong>UI Port</strong>
                                    <pre><code class="language-properties">
# Default 4040. If occupied, tries 4041, 4042...
spark.ui.port = 4050
                </code></pre>
                                </ol>
                            </ul>


                            <details open>
                                <summary>references">
                                    <h2>References</h2>
                                    <ul>
                                        <li><a href="https://spark.apache.org/docs/latest/configuration.html"
                                                target="_blank">Spark Configuration
                                                Docs</a></li>
                                        <li><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                                                target="_blank">Spark
                                                Performance Tuning</a></li>
                                    </ul>

</body>

</html>